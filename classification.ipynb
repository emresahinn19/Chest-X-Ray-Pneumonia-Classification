{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c6ce72c-46cb-4af6-8f33-fa2d897d85c9",
      "metadata": {
        "id": "2c6ce72c-46cb-4af6-8f33-fa2d897d85c9"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchxrayvision"
      ],
      "metadata": {
        "id": "5EtfiEK7wydK"
      },
      "id": "5EtfiEK7wydK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63ab1136-afe5-4104-a162-594972d9166a",
      "metadata": {
        "id": "63ab1136-afe5-4104-a162-594972d9166a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import skimage\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import torchxrayvision as xrv\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35e980af-30ae-4293-8183-ee5113eb9ef9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35e980af-30ae-4293-8183-ee5113eb9ef9",
        "outputId": "a64ec023-a696-41f6-fd35-18a2e859feff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading weights...\n",
            "If this fails you can run `wget https://github.com/mlmed/torchxrayvision/releases/download/v1/pspnet_chestxray_best_model_4.pth -O /root/.torchxrayvision/models_data/pspnet_chestxray_best_model_4.pth`\n",
            "[██████████████████████████████████████████████████]\n"
          ]
        }
      ],
      "source": [
        "model = xrv.baseline_models.chestx_det.PSPNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f97b9b5-d26c-430f-a8f1-9c5d9e34f8be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f97b9b5-d26c-430f-a8f1-9c5d9e34f8be",
        "outputId": "7306e053-7d2c-4f6d-dccc-33c3f1cc266c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "chestx-det-pspnet"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "model #I used torchxrayvision PSPNET segmentation model for the localizing the Chest parts of the X-ray images.\n",
        "      #Unfortunately, I'm not able to provide code of the segmentetaion part because of privacy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#HISTOGRAM EQUALIZATION\n",
        "\n",
        "import cv2\n",
        "input_folder = \"/content/train-NORMAL/NORMAL\"\n",
        "\n",
        "output_path = \"train-NORMAL-son\"\n",
        "\n",
        "if not os.path.exists(output_path):\n",
        "  os.makedirs(output_path)\n",
        "\n",
        "\n",
        "for filename in os.listdir(input_folder):\n",
        "\n",
        "    file_path = os.path.join(input_folder, filename)\n",
        "\n",
        "\n",
        "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "\n",
        "    img_equalized = cv2.equalizeHist(img)\n",
        "\n",
        "\n",
        "    output_folder = os.path.join(output_path, filename)\n",
        "    cv2.imwrite(output_folder, img_equalized)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4Z7Zq9XD6f_H"
      },
      "id": "4Z7Zq9XD6f_H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras import layers, models\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.layers import Input, Activation\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Add, AveragePooling2D\n",
        "from tensorflow.keras.layers import ReLU, Flatten, Dense,Dropout\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from matplotlib.colors import ListedColormap\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import keras\n",
        "import sklearn.metrics.pairwise\n",
        "import sklearn as sk\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import matplotlib as mpl\n",
        "import os\n",
        "import scipy.io\n",
        "import cv2"
      ],
      "metadata": {
        "id": "w3yC9aO_LR7c"
      },
      "id": "w3yC9aO_LR7c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRAD-CAM"
      ],
      "metadata": {
        "id": "4bm0FciiLW8r"
      },
      "id": "4bm0FciiLW8r"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_img_arr(img_path,size):\n",
        "\n",
        "\n",
        " img = keras.utils.load_img(img_path, target_size=size)\n",
        "\n",
        "\n",
        " array = keras.utils.img_to_array(img)\n",
        "\n",
        "\n",
        " array = np.expand_dims(array, axis=0)\n",
        "\n",
        "\n",
        " return array"
      ],
      "metadata": {
        "id": "1sQksDQILbnT"
      },
      "id": "1sQksDQILbnT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradcam_heatmap(img_array,model, last_conv_layer_name, pred_index=None):\n",
        "\n",
        "\n",
        " last_conv_layer = model.get_layer(last_conv_layer_name)\n",
        "\n",
        " grad_model = keras.models.Model(\n",
        "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        " with tf.GradientTape() as tape:\n",
        "  last_layer_conv_outputs, preds = grad_model(img_array)\n",
        "  if pred_index is None:\n",
        "    pred_index = tf.argmax(preds[0])\n",
        "  class_channel = preds[:, pred_index]\n",
        "\n",
        " grads = tape.gradient(class_channel, last_layer_conv_outputs)\n",
        "\n",
        " pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        " last_layer_conv_outputs = last_layer_conv_outputs[0]\n",
        " heatmap = last_layer_conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "\n",
        " heatmap = tf.squeeze(heatmap)\n",
        "\n",
        " heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        " return heatmap.numpy()"
      ],
      "metadata": {
        "id": "ApJSQW-9Ldr7"
      },
      "id": "ApJSQW-9Ldr7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATASET AND MODEL"
      ],
      "metadata": {
        "id": "0Ya2cYGgLiME"
      },
      "id": "0Ya2cYGgLiME"
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(horizontal_flip=True,\n",
        "                                   vertical_flip=True,\n",
        "                                   rotation_range=30,\n",
        "                                   brightness_range=[0.8,1.5],\n",
        "                                   zoom_range = 0.25,\n",
        "                                   preprocessing_function= keras.applications.vgg19.preprocess_input,\n",
        "                                   fill_mode='constant'\n",
        "                                   )\n",
        "train_generator1 = train_datagen.flow_from_directory(\n",
        "    directory=\"/content/dataset/train\",\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    seed = 6,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle=True,\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator(preprocessing_function= keras.applications.vgg19.preprocess_input\n",
        "\n",
        "                                 )\n",
        "\n",
        "test_generator1 = test_datagen.flow_from_directory(\n",
        "    directory=\"/content/dataset/test\",\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    seed=6,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "j_oMZB1aLoLE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "674ff507-a144-4e13-e23e-5fc0dc5fdb31"
      },
      "id": "j_oMZB1aLoLE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_input = Input(shape=(224, 224, 3))\n",
        "model1 = keras.applications.VGG19(weights='imagenet', include_top=False, input_tensor=new_input)\n",
        "\n",
        "\n",
        "for layer in model1.layers[1:]:\n",
        "  layer.trainable=True\n",
        "\n",
        "\n",
        "flat1 = keras.layers.Flatten()(model1.layers[-1].output)\n",
        "\n",
        "\n",
        "x = Dense(256, activation='relu')(flat1)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model2 = Model(inputs=model1.inputs, outputs=output)\n",
        "keras.utils.plot_model(model1, show_shapes=True, show_trainable=True)\n",
        "model2.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "NFnOdQfOLqRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3046e7eb-17db-458b-94f5-fe6f1eba33e1"
      },
      "id": "NFnOdQfOLqRb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 2s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               6422784   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26480193 (101.01 MB)\n",
            "Trainable params: 26480193 (101.01 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy',tf.keras.metrics.TruePositives(thresholds=0.5),\n",
        "             tf.keras.metrics.TrueNegatives(thresholds=0.5),\n",
        "             tf.keras.metrics.FalseNegatives(thresholds=0.5),\n",
        "             tf.keras.metrics.FalsePositives(thresholds=0.5),\n",
        "             tf.keras.metrics.F1Score()\n", 
        "           ]\n",
        ")\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=15,\n",
        "    min_delta=0.001,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "callbacks = [early_stopping]\n",
        "history = model2.fit(\n",
        "    train_generator1,\n",
        "    shuffle = True,\n",
        "    batch_size=32,\n",
        "\n",
        "    epochs=20,\n",
        "    verbose = 1\n",
        ")"
      ],
      "metadata": {
        "id": "RACUctZCLtZb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac44dfd1-277c-48c9-81af-af304367d8aa"
      },
      "id": "RACUctZCLtZb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "163/163 [==============================] - 120s 627ms/step - loss: 1.0782 - accuracy: 0.6449 - true_positives: 2980.0000 - true_negatives: 384.0000 - false_negatives: 895.0000 - false_positives: 957.0000 - f1_score: 0.8515\n",
            "Epoch 2/20\n",
            "163/163 [==============================] - 100s 612ms/step - loss: 0.4775 - accuracy: 0.7512 - true_positives: 3544.0000 - true_negatives: 374.0000 - false_negatives: 331.0000 - false_positives: 967.0000 - f1_score: 0.8525\n",
            "Epoch 3/20\n",
            "163/163 [==============================] - 101s 619ms/step - loss: 0.3510 - accuracy: 0.8313 - true_positives: 3531.0000 - true_negatives: 805.0000 - false_negatives: 344.0000 - false_positives: 536.0000 - f1_score: 0.8525\n",
            "Epoch 4/20\n",
            "163/163 [==============================] - 98s 601ms/step - loss: 0.3256 - accuracy: 0.8512 - true_positives: 3475.0000 - true_negatives: 965.0000 - false_negatives: 400.0000 - false_positives: 376.0000 - f1_score: 0.8525\n",
            "Epoch 5/20\n",
            "163/163 [==============================] - 99s 606ms/step - loss: 0.2876 - accuracy: 0.8715 - true_positives: 3550.0000 - true_negatives: 996.0000 - false_negatives: 325.0000 - false_positives: 345.0000 - f1_score: 0.8525\n",
            "Epoch 6/20\n",
            "163/163 [==============================] - 98s 603ms/step - loss: 0.2508 - accuracy: 0.8928 - true_positives: 3580.0000 - true_negatives: 1077.0000 - false_negatives: 295.0000 - false_positives: 264.0000 - f1_score: 0.8525\n",
            "Epoch 7/20\n",
            "163/163 [==============================] - 98s 603ms/step - loss: 0.2478 - accuracy: 0.9028 - true_positives: 3595.0000 - true_negatives: 1114.0000 - false_negatives: 280.0000 - false_positives: 227.0000 - f1_score: 0.8525\n",
            "Epoch 8/20\n",
            "163/163 [==============================] - 97s 594ms/step - loss: 0.2385 - accuracy: 0.9078 - true_positives: 3619.0000 - true_negatives: 1116.0000 - false_negatives: 256.0000 - false_positives: 225.0000 - f1_score: 0.8525\n",
            "Epoch 9/20\n",
            "163/163 [==============================] - 99s 604ms/step - loss: 0.2130 - accuracy: 0.9181 - true_positives: 3642.0000 - true_negatives: 1147.0000 - false_negatives: 233.0000 - false_positives: 194.0000 - f1_score: 0.8525\n",
            "Epoch 10/20\n",
            "163/163 [==============================] - 98s 600ms/step - loss: 0.2101 - accuracy: 0.9181 - true_positives: 3623.0000 - true_negatives: 1166.0000 - false_negatives: 252.0000 - false_positives: 175.0000 - f1_score: 0.8525\n",
            "Epoch 11/20\n",
            "163/163 [==============================] - 99s 609ms/step - loss: 0.1913 - accuracy: 0.9252 - true_positives: 3653.0000 - true_negatives: 1173.0000 - false_negatives: 222.0000 - false_positives: 168.0000 - f1_score: 0.8525\n",
            "Epoch 12/20\n",
            "163/163 [==============================] - 98s 602ms/step - loss: 0.2062 - accuracy: 0.9202 - true_positives: 3635.0000 - true_negatives: 1165.0000 - false_negatives: 240.0000 - false_positives: 176.0000 - f1_score: 0.8525\n",
            "Epoch 13/20\n",
            "163/163 [==============================] - 97s 596ms/step - loss: 0.1902 - accuracy: 0.9271 - true_positives: 3663.0000 - true_negatives: 1173.0000 - false_negatives: 212.0000 - false_positives: 168.0000 - f1_score: 0.8525\n",
            "Epoch 14/20\n",
            "163/163 [==============================] - 98s 603ms/step - loss: 0.1803 - accuracy: 0.9317 - true_positives: 3678.0000 - true_negatives: 1182.0000 - false_negatives: 197.0000 - false_positives: 159.0000 - f1_score: 0.8525\n",
            "Epoch 15/20\n",
            "163/163 [==============================] - 98s 599ms/step - loss: 0.1776 - accuracy: 0.9346 - true_positives: 3676.0000 - true_negatives: 1199.0000 - false_negatives: 199.0000 - false_positives: 142.0000 - f1_score: 0.8525\n",
            "Epoch 16/20\n",
            "163/163 [==============================] - 98s 603ms/step - loss: 0.1780 - accuracy: 0.9363 - true_positives: 3680.0000 - true_negatives: 1204.0000 - false_negatives: 195.0000 - false_positives: 137.0000 - f1_score: 0.8525\n",
            "Epoch 17/20\n",
            "163/163 [==============================] - 98s 601ms/step - loss: 0.1636 - accuracy: 0.9417 - true_positives: 3703.0000 - true_negatives: 1209.0000 - false_negatives: 172.0000 - false_positives: 132.0000 - f1_score: 0.8525\n",
            "Epoch 18/20\n",
            "163/163 [==============================] - 100s 611ms/step - loss: 0.1642 - accuracy: 0.9387 - true_positives: 3695.0000 - true_negatives: 1201.0000 - false_negatives: 180.0000 - false_positives: 140.0000 - f1_score: 0.8525\n",
            "Epoch 19/20\n",
            "163/163 [==============================] - 98s 598ms/step - loss: 0.1583 - accuracy: 0.9423 - true_positives: 3716.0000 - true_negatives: 1199.0000 - false_negatives: 159.0000 - false_positives: 142.0000 - f1_score: 0.8525\n",
            "Epoch 20/20\n",
            "163/163 [==============================] - 98s 602ms/step - loss: 0.1627 - accuracy: 0.9402 - true_positives: 3694.0000 - true_negatives: 1210.0000 - false_negatives: 181.0000 - false_positives: 131.0000 - f1_score: 0.8525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL COMPILING AND TESTING"
      ],
      "metadata": {
        "id": "YZWG5DXBLxTK"
      },
      "id": "YZWG5DXBLxTK"
    },
    {
      "cell_type": "code",
      "source": [
        "result = model2.evaluate(test_generator1,verbose='auto',batch_size=32)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "h6484R1GL_5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "413cca59-3dc6-4510-844f-5c0cdea5c93a"
      },
      "id": "h6484R1GL_5D",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 5s 243ms/step - loss: 0.1665 - accuracy: 0.9391 - true_positives: 387.0000 - true_negatives: 199.0000 - false_negatives: 3.0000 - false_positives: 35.0000 - f1_score: 0.7692\n",
            "[0.16647474467754364, 0.9391025900840759, 387.0, 199.0, 3.0, 35.0, array([0.7692308], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRAD-CAM HEATMAP AND VISUALIZING"
      ],
      "metadata": {
        "id": "xR-fOVN0MI0U"
      },
      "id": "xR-fOVN0MI0U"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img_size = (224, 224)\n",
        "preprocess_input = keras.applications.efficientnet.preprocess_input\n",
        "\n",
        "\n",
        "last_conv_layer_name = \"top_activation\"\n",
        "\n",
        "\n",
        "img_path = \"/content/dataset/test/NORMAL/NORMAL2-IM-0221-0001.png\"\n",
        "\n",
        "\n",
        "\n",
       
        "img_array = preprocess_input(get_img_arr(img_path, size=img_size))\n",
        "print(img_array.shape)\n",
        
        "model = model1\n",
        "\n",
        "model.layers[-1].activation = None\n",
        "\n",
        
        "class_label = ['NORMAL','PNEUMONIA']\n",
        "\n",
        "preds = model.predict(img_array)\n",
        "\n",
        "predicted_class_index = np.argmax(preds[0]) #üstteki pred_index=None olmalı.\n",
        "predicted_class_label = class_label[predicted_class_index]\n",
        "\n",
        "\n",
        "\n",
        "print(\"Predicted class:\", predicted_class_label)\n",
        "\n",
        "heatmap = gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "plt.matshow(heatmap)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YCgeFysRMOiz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "8c6785c7-9d3d-426b-e043-af08dd84b2aa"
      },
      "id": "YCgeFysRMOiz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 224, 224, 3)\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "Predicted class: NORMAL\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.5):\n",
        "    img = keras.utils.load_img(img_path)\n",
        "    img = keras.utils.img_to_array(img)\n",
        "\n",
        "    jet = mpl.colormaps['jet']\n",
        "\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    jet_color = jet(np.arange(256))[:,:3]\n",
        "    jet_heatmap = jet_color[heatmap]\n",
        "\n",
        "    jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1],img.shape[0]))\n",
        "    jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
        "\n",
        "    print(img.shape)\n",
        "    print(jet_heatmap.shape)\n",
        "    birlesmis_img = jet_heatmap * alpha + img\n",
        "    birlesmis_img = keras.utils.array_to_img(birlesmis_img)\n",
        "\n",
        
        "    birlesmis_img.save(\"cam.jpg\")\n",
        "\n",
        "\n",
        "    birlesmis_img = keras.utils.load_img(cam_path)\n",
        "    birlesmis_img = keras.utils.img_to_array(birlesmis_img)\n",
        "\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    axes[0].imshow(img / 255)\n",
        "    axes[0].set_title('Original Image')\n",
        "    axes[0].axis('off')\n",
        "    axes[1].imshow(birlesmis_img / 255)\n",
        "    axes[1].set_title('Grad-CAM Image')\n",
        "    axes[1].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "save_and_display_gradcam(img_path, heatmap)"
      ],
      "metadata": {
        "id": "aTtbcvp7MWT6"
      },
      "id": "aTtbcvp7MWT6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL GRAPHS"
      ],
      "metadata": {
        "id": "oylmTbzGMbGE"
      },
      "id": "oylmTbzGMbGE"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
